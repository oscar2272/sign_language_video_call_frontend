import React, { useEffect, useRef, useState } from "react";
import { Button } from "~/common/components/ui/button";
import { useOutletContext, useNavigate } from "react-router";
import type { UserProfile } from "~/features/profiles/type";
import type { Route } from "./+types/call-page";

// MediaPipe íƒ€ì… ì •ì˜
declare global {
  interface Window {
    MediaPipe: any;
  }
}

export const loader = async ({ params }: Route.LoaderArgs) => {
  console.log("roomId:", params.id);
  return { roomId: params.id || null };
};

const BASE_URL = import.meta.env.VITE_API_BASE_URL;
const CALL_API_URL = `${BASE_URL}/api/calls`;
const WS_BASE_URL =
  import.meta.env.VITE_WS_BASE_URL ?? `ws://${window.location.hostname}:8000`;
const AI_WS_URL = `${WS_BASE_URL}/ai`;

export default function CallPage({ loaderData }: Route.ComponentProps) {
  const { roomId } = loaderData;
  const navigate = useNavigate();
  const { user, token } = useOutletContext<{
    user: UserProfile;
    token: string;
  }>();

  // ê¸°ì¡´ ìƒíƒœë“¤
  const [localStream, setLocalStream] = useState<MediaStream | null>(null);
  const [remoteStream, setRemoteStream] = useState<MediaStream | null>(null);
  const [callStatus, setCallStatus] = useState<
    "calling" | "connecting" | "connected" | "rejected" | "ended"
  >("calling");
  const [isCameraOn, setIsCameraOn] = useState(true);
  const [isMicOn, setIsMicOn] = useState(true);
  const [connectionTime, setConnectionTime] = useState(0);
  const [debugInfo, setDebugInfo] = useState<string[]>([]);

  // AI ê¸°ëŠ¥ ìƒíƒœë“¤
  const [isAIEnabled, setIsAIEnabled] = useState(false);
  const [aiStatus, setAiStatus] = useState<
    "disconnected" | "connecting" | "connected"
  >("disconnected");
  const [handLandmarks, setHandLandmarks] = useState<any[]>([]);
  const [mediaPipeLoaded, setMediaPipeLoaded] = useState(false);
  const [remoteAIEnabled, setRemoteAIEnabled] = useState(false);

  // Refs
  const localVideoRef = useRef<HTMLVideoElement>(null);
  const remoteVideoRef = useRef<HTMLVideoElement>(null);
  const wsRef = useRef<WebSocket | null>(null);
  const aiWsRef = useRef<WebSocket | null>(null);
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const connectionTimeRef = useRef<NodeJS.Timeout | null>(null);
  const pendingCandidatesRef = useRef<RTCIceCandidateInit[]>([]);
  const localStreamRef = useRef<MediaStream | null>(null);

  // MediaPipe refs
  const holisticRef = useRef<any>(null);
  const cameraRef = useRef<any>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);

  // ë””ë²„ê·¸ ë¡œê·¸ í•¨ìˆ˜
  const addDebugLog = (message: string) => {
    console.log(`[CallPage] ${message}`);
    setDebugInfo((prev) => [
      ...prev.slice(-10), // ë” ë§ì€ ë¡œê·¸ í‘œì‹œ
      `${new Date().toLocaleTimeString()}: ${message}`,
    ]);
  };

  // MediaPipe ìŠ¤í¬ë¦½íŠ¸ ë¡œë”© (ìˆœì°¨ì ìœ¼ë¡œ)
  const loadMediaPipeScripts = (): Promise<void> => {
    return new Promise((resolve, reject) => {
      const scripts = [
        "https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3.1640029074/camera_utils.js",
        "https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3.1640029074/drawing_utils.js",
        "https://cdn.jsdelivr.net/npm/@mediapipe/holistic@0.5.1635989137/holistic.js",
      ];

      let loadedCount = 0;

      const loadScript = (src: string) => {
        return new Promise<void>((resolve, reject) => {
          if (document.querySelector(`script[src="${src}"]`)) {
            resolve();
            return;
          }

          const script = document.createElement("script");
          script.src = src;
          script.onload = () => {
            addDebugLog(`Loaded: ${src.split("/").pop()}`);
            resolve();
          };
          script.onerror = () => {
            addDebugLog(`Failed to load: ${src.split("/").pop()}`);
            reject(new Error(`Failed to load ${src}`));
          };
          document.head.appendChild(script);
        });
      };

      // ìˆœì°¨ì ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ
      const loadSequentially = async () => {
        try {
          for (const src of scripts) {
            await loadScript(src);
            loadedCount++;
          }

          // ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ ì™„ë£Œ í›„ ì•½ê°„ ëŒ€ê¸°
          setTimeout(() => {
            if (window.MediaPipe?.Holistic && window.MediaPipe?.Camera) {
              addDebugLog("All MediaPipe scripts loaded successfully");
              setMediaPipeLoaded(true);
              resolve();
            } else {
              addDebugLog("MediaPipe objects not found after loading");
              reject(new Error("MediaPipe objects not available"));
            }
          }, 500);
        } catch (error) {
          reject(error);
        }
      };

      loadSequentially();
    });
  };

  // MediaPipe Holistic ì´ˆê¸°í™”
  const initializeHolistic = async () => {
    try {
      if (!window.MediaPipe?.Holistic) {
        addDebugLog("MediaPipe.Holistic not available");
        return;
      }

      addDebugLog("Initializing Holistic...");

      const holistic = new window.MediaPipe.Holistic({
        locateFile: (file: string) => {
          return `https://cdn.jsdelivr.net/npm/@mediapipe/holistic@0.5.1635989137/${file}`;
        },
      });

      holistic.setOptions({
        selfieMode: true,
        modelComplexity: 1,
        smoothLandmarks: true,
        enableSegmentation: false, // ì†ë§Œ í•„ìš”í•˜ë¯€ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë„ê¸°
        smoothSegmentation: false,
        refineFaceLandmarks: false, // ì–¼êµ´ë„ ë„ê¸°
        minDetectionConfidence: 0.7,
        minTrackingConfidence: 0.5,
      });

      holistic.onResults(onHolisticResults);
      holisticRef.current = holistic;

      addDebugLog("Holistic initialized successfully");
      return holistic;
    } catch (error) {
      addDebugLog(`Holistic initialization error: ${error}`);
      return null;
    }
  };

  // ì† ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬
  const onHolisticResults = (results: any) => {
    // ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
    drawResults(results);

    // ì† ì¢Œí‘œ ì¶”ì¶œ
    const landmarks: any[] = [];

    if (results.leftHandLandmarks) {
      const leftHand: Array<{ x: number; y: number }> = [];
      for (let i = 0; i < results.leftHandLandmarks.length; i++) {
        leftHand.push({
          x: results.leftHandLandmarks[i].x,
          y: results.leftHandLandmarks[i].y,
        });
      }
      landmarks.push(leftHand);
    }

    if (results.rightHandLandmarks) {
      const rightHand: Array<{ x: number; y: number }> = [];
      for (let i = 0; i < results.rightHandLandmarks.length; i++) {
        rightHand.push({
          x: results.rightHandLandmarks[i].x,
          y: results.rightHandLandmarks[i].y,
        });
      }
      landmarks.push(rightHand);
    }

    setHandLandmarks(landmarks);

    // AI WebSocketìœ¼ë¡œ ì „ì†¡
    if (
      isAIEnabled &&
      aiWsRef.current?.readyState === WebSocket.OPEN &&
      landmarks.length > 0
    ) {
      const message = {
        type: "hand_landmarks",
        room_id: roomId,
        landmarks: landmarks,
        timestamp: Date.now(),
      };

      try {
        aiWsRef.current.send(JSON.stringify(message));
        addDebugLog(
          `âœ… Sent ${landmarks.length} hands to AI (${landmarks.reduce((sum, hand) => sum + hand.length, 0)} points)`
        );
      } catch (error) {
        addDebugLog(`âŒ Failed to send landmarks: ${error}`);
      }
    }
  };

  // ìº”ë²„ìŠ¤ì— ê²°ê³¼ ê·¸ë¦¬ê¸°
  const drawResults = (results: any) => {
    if (!canvasRef.current || !localVideoRef.current) return;

    const videoWidth = localVideoRef.current.videoWidth;
    const videoHeight = localVideoRef.current.videoHeight;

    if (videoWidth === 0 || videoHeight === 0) return;

    canvasRef.current.width = videoWidth;
    canvasRef.current.height = videoHeight;

    const canvasCtx = canvasRef.current.getContext("2d");
    if (!canvasCtx) return;

    canvasCtx.save();
    canvasCtx.clearRect(
      0,
      0,
      canvasRef.current.width,
      canvasRef.current.height
    );

    // ë¹„ë””ì˜¤ ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°
    canvasCtx.globalCompositeOperation = "destination-atop";
    canvasCtx.drawImage(
      results.image,
      0,
      0,
      canvasRef.current.width,
      canvasRef.current.height
    );

    canvasCtx.globalCompositeOperation = "source-over";

    // ì† ê·¸ë¦¬ê¸°
    if (window.MediaPipe?.drawConnectors && window.MediaPipe?.drawLandmarks) {
      if (results.leftHandLandmarks) {
        window.MediaPipe.drawConnectors(
          canvasCtx,
          results.leftHandLandmarks,
          window.MediaPipe.HAND_CONNECTIONS,
          { color: "#CC0000", lineWidth: 5 }
        );
        window.MediaPipe.drawLandmarks(canvasCtx, results.leftHandLandmarks, {
          color: "#00FF00",
          lineWidth: 2,
        });
      }

      if (results.rightHandLandmarks) {
        window.MediaPipe.drawConnectors(
          canvasCtx,
          results.rightHandLandmarks,
          window.MediaPipe.HAND_CONNECTIONS,
          { color: "#00CC00", lineWidth: 5 }
        );
        window.MediaPipe.drawLandmarks(canvasCtx, results.rightHandLandmarks, {
          color: "#FF0000",
          lineWidth: 2,
        });
      }
    }

    canvasCtx.restore();
  };

  // ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
  const startCamera = async () => {
    if (!holisticRef.current || !localVideoRef.current) {
      addDebugLog("Holistic or video ref not ready");
      return;
    }

    try {
      addDebugLog("Starting MediaPipe camera...");

      if (window.MediaPipe?.Camera) {
        const camera = new window.MediaPipe.Camera(localVideoRef.current, {
          onFrame: async () => {
            if (!localVideoRef.current || !holisticRef.current) return;
            await holisticRef.current.send({ image: localVideoRef.current });
          },
          width: 640,
          height: 480,
        });

        cameraRef.current = camera;
        camera.start();
        addDebugLog("MediaPipe camera started");
      } else {
        addDebugLog("MediaPipe.Camera not available");
      }
    } catch (error) {
      addDebugLog(`Camera start error: ${error}`);
    }
  };

  // AI WebSocket ì—°ê²°
  const connectAIWebSocket = () => {
    try {
      addDebugLog("Connecting to AI WebSocket...");
      setAiStatus("connecting");

      const aiWs = new WebSocket(`${AI_WS_URL}?role=client&room=${roomId}`);

      aiWs.onopen = () => {
        addDebugLog("ğŸŸ¢ AI WebSocket connected");
        setAiStatus("connected");
      };

      aiWs.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          addDebugLog(`ğŸ“¤ AI response: ${data.type}`);

          if (data.type === "ai_result") {
            addDebugLog(
              `ğŸ”¤ AI translation: ${data.text || data.result || "No text"}`
            );
          }

          // ìƒëŒ€ë°©ì˜ AI ìƒíƒœ ë³€ê²½ ì•Œë¦¼ ì²˜ë¦¬
          if (data.type === "ai_status_change" && data.user_id !== user.id) {
            setRemoteAIEnabled(data.ai_enabled);
            addDebugLog(
              `ğŸ‘¥ Remote user ${data.ai_enabled ? "enabled" : "disabled"} AI`
            );
          }
        } catch (error) {
          addDebugLog(`âŒ AI message parse error: ${error}`);
        }
      };

      aiWs.onclose = () => {
        addDebugLog("ğŸ”´ AI WebSocket disconnected");
        setAiStatus("disconnected");
      };

      aiWs.onerror = (error) => {
        addDebugLog(`âŒ AI WebSocket error: ${error}`);
        setAiStatus("disconnected");
      };

      aiWsRef.current = aiWs;
    } catch (error) {
      addDebugLog(`âŒ AI WebSocket connection error: ${error}`);
      setAiStatus("disconnected");
    }
  };

  // AI ê¸°ëŠ¥ í† ê¸€
  const toggleAI = async () => {
    // ìƒëŒ€ë°©ì´ ì´ë¯¸ AIë¥¼ ì¼°ìœ¼ë©´ ë§‰ê¸°
    if (!isAIEnabled && remoteAIEnabled) {
      addDebugLog("âŒ Cannot enable AI: Remote user already has AI enabled");
      alert("ìƒëŒ€ë°©ì´ ì´ë¯¸ AI ê¸°ëŠ¥ì„ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.");
      return;
    }

    if (isAIEnabled) {
      // AI ë„ê¸°
      setIsAIEnabled(false);
      if (aiWsRef.current?.readyState === WebSocket.OPEN) {
        // ìƒëŒ€ë°©ì—ê²Œ AI êº¼ì§ ì•Œë¦¼
        aiWsRef.current.send(
          JSON.stringify({
            type: "ai_status_change",
            user_id: user.id,
            ai_enabled: false,
          })
        );
        aiWsRef.current.close();
        aiWsRef.current = null;
      }

      if (cameraRef.current) {
        cameraRef.current.stop?.();
        cameraRef.current = null;
      }

      setAiStatus("disconnected");
      addDebugLog("ğŸ”´ AI feature disabled");
    } else {
      // AI ì¼œê¸°
      if (!mediaPipeLoaded) {
        addDebugLog("â³ Loading MediaPipe first...");
        try {
          await loadMediaPipeScripts();
          await initializeHolistic();
        } catch (error) {
          addDebugLog(`âŒ MediaPipe loading failed: ${error}`);
          return;
        }
      }

      setIsAIEnabled(true);
      addDebugLog("ğŸŸ¢ AI feature enabled");

      // AI WebSocket ì—°ê²°
      connectAIWebSocket();

      // ìƒëŒ€ë°©ì—ê²Œ AI ì¼œì§ ì•Œë¦¼ (WebSocket ì—°ê²° í›„)
      setTimeout(() => {
        if (aiWsRef.current?.readyState === WebSocket.OPEN) {
          aiWsRef.current.send(
            JSON.stringify({
              type: "ai_status_change",
              user_id: user.id,
              ai_enabled: true,
            })
          );
        }
      }, 1000);

      // ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
      setTimeout(() => {
        startCamera();
      }, 1500);
    }
  };

  // WebRTC ì„¤ì • (ê¸°ì¡´ ì½”ë“œ)
  const createPeerConnection = () => {
    addDebugLog("Creating peer connection...");

    const pc = new RTCPeerConnection({
      iceServers: [
        { urls: "stun:stun.l.google.com:19302" },
        { urls: "stun:stun1.l.google.com:19302" },
      ],
    });

    pc.onicecandidate = (event) => {
      if (event.candidate && wsRef.current?.readyState === WebSocket.OPEN) {
        addDebugLog("Sending ICE candidate");
        wsRef.current.send(
          JSON.stringify({
            type: "ice",
            candidate: event.candidate,
          })
        );
      } else if (!event.candidate) {
        addDebugLog("ICE gathering complete");
      }
    };

    pc.ontrack = (event) => {
      addDebugLog("Remote track received");
      setRemoteStream(event.streams[0]);
    };

    pc.onconnectionstatechange = () => {
      const state = pc.connectionState;
      addDebugLog(`Connection state changed: ${state}`);

      if (state === "connected") {
        setCallStatus("connected");
        startConnectionTimer();
      } else if (state === "failed" || state === "closed") {
        addDebugLog("Connection failed or closed, ending call");
        endCall();
      }
    };

    pc.onicegatheringstatechange = () => {
      addDebugLog(`ICE gathering state: ${pc.iceGatheringState}`);
    };

    pc.onsignalingstatechange = () => {
      addDebugLog(`Signaling state: ${pc.signalingState}`);
    };

    return pc;
  };

  // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” (ê¸°ì¡´ ì½”ë“œ)
  const initializeMedia = async (): Promise<MediaStream | null> => {
    try {
      addDebugLog("Requesting media access...");
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 1280, height: 720 },
        audio: true,
      });

      localStreamRef.current = stream;
      setLocalStream(stream);
      addDebugLog("Media access granted");

      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
      }

      return stream;
    } catch (error) {
      addDebugLog(`Media access error: ${error}`);
      alert("ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
      return null;
    }
  };

  // django WebSocket ì—°ê²° (ìˆ˜ì •ë¨ - AI ìƒíƒœ ì•Œë¦¼ ì²˜ë¦¬ ì¶”ê°€)
  const connectWebSocket = (stream: MediaStream) => {
    addDebugLog("Connecting to WebSocket...");
    const ws = new WebSocket(
      `${WS_BASE_URL}/ws/call/${roomId}/?user_id=${user.id}`
    );

    ws.onopen = () => {
      addDebugLog("WebSocket connected - ready for signaling");
      setCallStatus("connecting");
    };

    ws.onmessage = async (event) => {
      const data = JSON.parse(event.data);
      addDebugLog(`WebSocket message: ${data.type}`);

      switch (data.type) {
        case "user_joined":
          addDebugLog("User joined, creating offer");
          setCallStatus("connecting");
          setTimeout(() => createOffer(stream), 500);
          break;

        case "offer":
          addDebugLog("Received offer, handling...");
          await handleOffer(data.offer, stream);
          break;

        case "answer":
          addDebugLog("Received answer, handling...");
          await handleAnswer(data.answer);
          break;

        case "ice":
          addDebugLog("Received ICE candidate");
          await handleIceCandidate(data.candidate);
          break;

        case "ai_status_change":
          if (data.user_id !== user.id) {
            setRemoteAIEnabled(data.ai_enabled);
            addDebugLog(
              `ğŸ‘¥ Remote user ${data.ai_enabled ? "enabled" : "disabled"} AI`
            );
          }
          break;

        case "end_call":
          setCallStatus("ended");
          cleanup();
          setTimeout(() => navigate("/friends"), 2000);
          break;
      }
    };

    ws.onclose = () => {
      addDebugLog("WebSocket disconnected");
    };

    ws.onerror = (error) => {
      addDebugLog(`WebSocket error: ${error}`);
    };

    return ws;
  };

  // Offer ìƒì„± (ê¸°ì¡´ ì½”ë“œ)
  const createOffer = async (stream: MediaStream) => {
    addDebugLog("Creating offer...");

    if (!stream) {
      addDebugLog("Stream not provided to createOffer");
      return;
    }

    addDebugLog(`Stream ready with ${stream.getTracks().length} tracks`);

    const pc = createPeerConnection();
    pcRef.current = pc;

    stream.getTracks().forEach((track) => {
      addDebugLog(`Adding ${track.kind} track to peer connection`);
      pc.addTrack(track, stream);
    });

    try {
      const offer = await pc.createOffer({
        offerToReceiveAudio: true,
        offerToReceiveVideo: true,
      });

      await pc.setLocalDescription(offer);
      addDebugLog("Offer created and set as local description");

      if (wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.send(
          JSON.stringify({
            type: "offer",
            offer: offer,
          })
        );
        addDebugLog("Offer sent via WebSocket");
      } else {
        addDebugLog("WebSocket not ready, cannot send offer");
      }
    } catch (error) {
      addDebugLog(`Error creating offer: ${error}`);
    }
  };

  // Offer ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
  const handleOffer = async (
    offer: RTCSessionDescriptionInit,
    stream: MediaStream
  ) => {
    addDebugLog("Handling offer...");

    if (!stream) {
      addDebugLog("Stream not available for handling offer");
      return;
    }

    const pc = createPeerConnection();
    pcRef.current = pc;

    stream.getTracks().forEach((track) => {
      addDebugLog(`Adding ${track.kind} track to peer connection`);
      pc.addTrack(track, stream);
    });

    try {
      await pc.setRemoteDescription(new RTCSessionDescription(offer));
      addDebugLog("Remote description (offer) set");

      for (const candidate of pendingCandidatesRef.current) {
        await pc.addIceCandidate(new RTCIceCandidate(candidate));
        addDebugLog("Added pending ICE candidate");
      }
      pendingCandidatesRef.current = [];

      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);
      addDebugLog("Answer created and set as local description");

      if (wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.send(
          JSON.stringify({
            type: "answer",
            answer: answer,
          })
        );
        addDebugLog("Answer sent via WebSocket");
      }
    } catch (error) {
      addDebugLog(`Error handling offer: ${error}`);
    }
  };

  // Answer ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
  const handleAnswer = async (answer: RTCSessionDescriptionInit) => {
    addDebugLog("Handling answer...");

    if (!pcRef.current) {
      addDebugLog("PeerConnection not ready for handling answer");
      return;
    }

    try {
      await pcRef.current.setRemoteDescription(
        new RTCSessionDescription(answer)
      );
      addDebugLog("Remote description (answer) set successfully");

      for (const candidate of pendingCandidatesRef.current) {
        await pcRef.current.addIceCandidate(new RTCIceCandidate(candidate));
        addDebugLog("Added pending ICE candidate");
      }
      pendingCandidatesRef.current = [];
    } catch (error) {
      addDebugLog(`Error handling answer: ${error}`);
    }
  };

  // ICE Candidate ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
  const handleIceCandidate = async (candidate: RTCIceCandidateInit) => {
    if (!pcRef.current) {
      addDebugLog("PeerConnection not ready, storing ICE candidate");
      pendingCandidatesRef.current.push(candidate);
      return;
    }

    if (pcRef.current.remoteDescription) {
      try {
        await pcRef.current.addIceCandidate(new RTCIceCandidate(candidate));
        addDebugLog("ICE candidate added successfully");
      } catch (error) {
        addDebugLog(`Error adding ICE candidate: ${error}`);
      }
    } else {
      addDebugLog("Remote description not set, storing ICE candidate");
      pendingCandidatesRef.current.push(candidate);
    }
  };

  // ì—°ê²° ì‹œê°„ íƒ€ì´ë¨¸ (ê¸°ì¡´ ì½”ë“œ)
  const startConnectionTimer = () => {
    connectionTimeRef.current = setInterval(() => {
      setConnectionTime((prev) => prev + 1);
    }, 1000);
  };

  // í†µí™” ì¢…ë£Œ (ê¸°ì¡´ ì½”ë“œ)
  const endCall = async () => {
    addDebugLog("Ending call...");

    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: "end_call" }));
    }

    setCallStatus("ended");
    cleanup();

    try {
      await fetch(`${CALL_API_URL}/end/`, {
        method: "POST",
        headers: {
          Authorization: `Bearer ${token}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ room_id: roomId }),
      });
    } catch (err) {
      addDebugLog(`Failed to end call: ${err}`);
    }

    setTimeout(() => navigate("/friends"), 2000);
  };

  // ì¹´ë©”ë¼ í† ê¸€ (ê¸°ì¡´ ì½”ë“œ)
  const toggleCamera = () => {
    const stream = localStreamRef.current;
    if (stream) {
      const videoTrack = stream.getVideoTracks()[0];
      if (videoTrack) {
        videoTrack.enabled = !videoTrack.enabled;
        setIsCameraOn(videoTrack.enabled);
        addDebugLog(`Camera ${videoTrack.enabled ? "enabled" : "disabled"}`);
      }
    }
  };

  // ë§ˆì´í¬ í† ê¸€ (ê¸°ì¡´ ì½”ë“œ)
  const toggleMic = () => {
    const stream = localStreamRef.current;
    if (stream) {
      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = !audioTrack.enabled;
        setIsMicOn(audioTrack.enabled);
        addDebugLog(`Mic ${audioTrack.enabled ? "enabled" : "disabled"}`);
      }
    }
  };

  // ì •ë¦¬ í•¨ìˆ˜ (ìˆ˜ì •ë¨)
  const cleanup = () => {
    addDebugLog("Cleaning up resources...");

    if (connectionTimeRef.current) {
      clearInterval(connectionTimeRef.current);
    }

    if (cameraRef.current) {
      cameraRef.current.stop?.();
      cameraRef.current = null;
    }

    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach((track) => track.stop());
    }

    if (pcRef.current) {
      pcRef.current.close();
    }

    if (wsRef.current) {
      wsRef.current.close();
    }

    if (aiWsRef.current) {
      aiWsRef.current.close();
    }
  };

  // ì‹œê°„ í¬ë§·íŒ… (ê¸°ì¡´ ì½”ë“œ)
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, "0")}:${secs.toString().padStart(2, "0")}`;
  };

  // MediaPipe ì´ˆê¸°í™” (ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ)
  useEffect(() => {
    if (typeof window !== "undefined") {
      loadMediaPipeScripts().catch((error) => {
        addDebugLog(`MediaPipe loading failed: ${error}`);
      });
    }
  }, []);

  // ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ ì½”ë“œ)
  useEffect(() => {
    if (!roomId) {
      navigate("/friends");
      return;
    }

    addDebugLog("Initializing CallPage");

    const init = async () => {
      const stream = await initializeMedia();
      if (!stream) return;

      addDebugLog("Media stream ready, connecting WebSocket");
      wsRef.current = connectWebSocket(stream);
    };

    init();

    return cleanup;
  }, [roomId]);

  // ì›ê²© ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì„¤ì • (ê¸°ì¡´ ì½”ë“œ)
  useEffect(() => {
    if (remoteStream && remoteVideoRef.current) {
      remoteVideoRef.current.srcObject = remoteStream;
      addDebugLog("Remote stream set to video element");
    }
  }, [remoteStream]);

  return (
    <div className="fixed inset-0 bg-gray-900 flex flex-col h-screen">
      {/* ìƒíƒœ í‘œì‹œ */}
      <div className="bg-gray-800 text-white p-3 text-center flex-shrink-0 min-h-[60px] flex items-center justify-between">
        <div className="flex-1 text-center">
          {callStatus === "calling" && (
            <span className="text-sm sm:text-base">ì „í™” ê±°ëŠ” ì¤‘...</span>
          )}
          {callStatus === "connecting" && (
            <span className="text-sm sm:text-base">ì—°ê²° ì¤‘...</span>
          )}
          {callStatus === "connected" && (
            <span className="text-sm sm:text-base">
              í†µí™” ì¤‘ - {formatTime(connectionTime)}
            </span>
          )}
          {callStatus === "rejected" && (
            <span className="text-sm sm:text-base">í†µí™”ê°€ ê±°ì ˆë˜ì—ˆìŠµë‹ˆë‹¤</span>
          )}
          {callStatus === "ended" && (
            <span className="text-sm sm:text-base">í†µí™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤</span>
          )}
        </div>

        {/* AI ìƒíƒœ í‘œì‹œ */}
        <div className="text-xs flex items-center">
          <span
            className={`inline-block w-2 h-2 rounded-full mr-2 ${
              aiStatus === "connected"
                ? "bg-green-500"
                : aiStatus === "connecting"
                  ? "bg-yellow-500"
                  : "bg-red-500"
            }`}
          ></span>
          <span className="mr-3">AI: {aiStatus}</span>
          {mediaPipeLoaded && <span className="mr-3 text-green-400">MPâœ“</span>}
          {isAIEnabled && handLandmarks.length > 0 && (
            <span className="text-green-300">ğŸ‘‹ {handLandmarks.length}</span>
          )}
          {remoteAIEnabled && <span className="text-orange-300">ì›ê²©AI</span>}
        </div>
      </div>

      {/* ë””ë²„ê·¸ ì •ë³´ - ì¢Œí‘œê°’ ì‹¤ì‹œê°„ í‘œì‹œ */}
      <div className="bg-red-900 text-white p-2 text-xs flex-shrink-0 max-h-40 overflow-y-auto">
        {debugInfo.map((info, index) => (
          <div
            key={index}
            className={index === debugInfo.length - 1 ? "text-yellow-300" : ""}
          >
            {info}
          </div>
        ))}

        {/* ì‹¤ì‹œê°„ ì¢Œí‘œ ë””ë²„ê·¸ ì •ë³´ */}
        {isAIEnabled && handLandmarks.length > 0 && (
          <div className="text-green-300 mt-1 border-t border-green-700 pt-1">
            <div>ğŸ–ï¸ Hands detected: {handLandmarks.length}</div>
            {handLandmarks.map((hand, handIndex) => (
              <div key={handIndex} className="ml-2">
                Hand{handIndex + 1}: {hand.length} points | Wrist: (
                {hand[0]?.x?.toFixed(3)}, {hand[0]?.y?.toFixed(3)}) | Thumb: (
                {hand[4]?.x?.toFixed(3)}, {hand[4]?.y?.toFixed(3)}) | Index: (
                {hand[8]?.x?.toFixed(3)}, {hand[8]?.y?.toFixed(3)})
              </div>
            ))}
            <div className="text-xs text-gray-300">
              Total coordinates sent:{" "}
              {handLandmarks.reduce((sum, hand) => sum + hand.length, 0)} points
            </div>
          </div>
        )}
      </div>

      {/* ë¹„ë””ì˜¤ ì˜ì—­ */}
      <div
        className="flex-1 relative min-h-0"
        style={{ maxHeight: "calc(100vh - 240px)" }}
      >
        {/* ì›ê²© ë¹„ë””ì˜¤ (í° í™”ë©´) */}
        <video
          ref={remoteVideoRef}
          autoPlay
          playsInline
          className="w-full h-full object-cover"
          style={{ transform: "scaleX(-1)" }}
        />

        {/* ë¡œì»¬ ë¹„ë””ì˜¤ (ì‘ì€ í™”ë©´) */}
        <video
          ref={localVideoRef}
          autoPlay
          playsInline
          muted
          className={`absolute top-2 right-2 w-24 h-18 sm:w-32 sm:h-24 bg-gray-800 rounded-lg object-cover border-2 transition-colors ${
            isAIEnabled ? "border-green-400" : "border-white"
          }`}
          style={{ transform: "scaleX(-1)" }}
        />

        {/* MediaPipe ì† ì¸ì‹ ì˜¤ë²„ë ˆì´ ìº”ë²„ìŠ¤ */}
        <canvas
          ref={canvasRef}
          className={`absolute top-2 right-2 w-24 h-18 sm:w-32 sm:h-24 rounded-lg pointer-events-none ${
            isAIEnabled ? "opacity-70" : "opacity-0"
          } transition-opacity`}
          style={{ transform: "scaleX(-1)" }}
        />

        {/* ì—°ê²° ëŒ€ê¸° ì¤‘ì¼ ë•Œ í”Œë ˆì´ìŠ¤í™€ë” */}
        {!remoteStream &&
          callStatus !== "ended" &&
          callStatus !== "rejected" && (
            <div className="absolute inset-0 flex items-center justify-center text-white text-lg sm:text-xl">
              ìƒëŒ€ë°©ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...
            </div>
          )}
      </div>

      {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
      <div className="bg-gray-800 flex-shrink-0 p-3 sm:p-4 min-h-[100px] flex items-center justify-center">
        <div className="flex justify-center gap-2 sm:gap-4 w-full max-w-2xl">
          <Button
            onClick={toggleMic}
            variant={isMicOn ? "default" : "destructive"}
            className="flex-1 max-w-[100px] px-2 py-2 text-xs sm:text-sm sm:px-4"
          >
            <span className="hidden sm:inline">
              {isMicOn ? "ë§ˆì´í¬ ì¼œì§" : "ë§ˆì´í¬ êº¼ì§"}
            </span>
            <span className="sm:hidden">{isMicOn ? "ğŸ¤" : "ğŸ”‡"}</span>
          </Button>

          <Button
            onClick={toggleCamera}
            variant={isCameraOn ? "default" : "destructive"}
            className="flex-1 max-w-[100px] px-2 py-2 text-xs sm:text-sm sm:px-4"
          >
            <span className="hidden sm:inline">
              {isCameraOn ? "ì¹´ë©”ë¼ ì¼œì§" : "ì¹´ë©”ë¼ êº¼ì§"}
            </span>
            <span className="sm:hidden">{isCameraOn ? "ğŸ“¹" : "ğŸ“·"}</span>
          </Button>

          {/* AI ê¸°ëŠ¥ í† ê¸€ ë²„íŠ¼ - ìƒëŒ€ë°©ì´ AI ì¼œë©´ ë¹„í™œì„±í™” */}
          <Button
            onClick={toggleAI}
            disabled={remoteAIEnabled && !isAIEnabled}
            variant={isAIEnabled ? "default" : "outline"}
            className={`flex-1 max-w-[100px] px-2 py-2 text-xs sm:text-sm sm:px-4 ${
              isAIEnabled ? "bg-green-600 hover:bg-green-700" : ""
            } ${remoteAIEnabled && !isAIEnabled ? "opacity-50 cursor-not-allowed" : ""}`}
          >
            <span className="hidden sm:inline">
              {isAIEnabled
                ? "AI ì¼œì§"
                : remoteAIEnabled
                  ? "AI ì‚¬ìš©ì¤‘"
                  : "AI ë„ê¸°"}
            </span>
            <span className="sm:hidden">
              {isAIEnabled ? "ğŸ¤–" : remoteAIEnabled ? "â³" : "ğŸ”‡"}
            </span>
          </Button>

          <Button
            onClick={endCall}
            variant="destructive"
            className="flex-1 max-w-[100px] px-2 py-2 text-xs sm:text-sm sm:px-4 bg-red-600 hover:bg-red-700"
          >
            <span className="hidden sm:inline">í†µí™” ì¢…ë£Œ</span>
            <span className="sm:hidden">ğŸ“</span>
          </Button>
        </div>
      </div>
    </div>
  );
}

// MediaPipe ìŠ¤í¬ë¦½íŠ¸ ë¡œë”© í•¨ìˆ˜ë¥¼ ì»´í¬ë„ŒíŠ¸ ì™¸ë¶€ë¡œ ë¶„ë¦¬
const loadMediaPipeScripts = (): Promise<void> => {
  return new Promise((resolve, reject) => {
    // ì´ë¯¸ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if (window.MediaPipe?.Holistic && window.MediaPipe?.Camera) {
      resolve();
      return;
    }

    const scripts = [
      "https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3.1640029074/camera_utils.js",
      "https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3.1640029074/drawing_utils.js",
      "https://cdn.jsdelivr.net/npm/@mediapipe/holistic@0.5.1635989137/holistic.js",
    ];

    let loadedCount = 0;
    const totalCount = scripts.length;

    const loadScript = (src: string): Promise<void> => {
      return new Promise((resolve, reject) => {
        // ì´ë¯¸ ìˆëŠ” ìŠ¤í¬ë¦½íŠ¸ì¸ì§€ í™•ì¸
        if (document.querySelector(`script[src="${src}"]`)) {
          resolve();
          return;
        }

        const script = document.createElement("script");
        script.src = src;
        script.async = true;
        script.crossOrigin = "anonymous";

        script.onload = () => {
          console.log(`âœ… Loaded: ${src.split("/").pop()}`);
          resolve();
        };

        script.onerror = () => {
          console.error(`âŒ Failed to load: ${src.split("/").pop()}`);
          reject(new Error(`Failed to load ${src}`));
        };

        document.head.appendChild(script);
      });
    };

    // ìˆœì°¨ì ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ
    const loadSequentially = async () => {
      try {
        for (const src of scripts) {
          await loadScript(src);
          loadedCount++;
        }

        // ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ ì™„ë£Œ í›„ MediaPipe ê°ì²´ í™•ì¸
        let retries = 0;
        const maxRetries = 20;

        const checkMediaPipe = () => {
          if (
            window.MediaPipe?.Holistic &&
            window.MediaPipe?.Camera &&
            window.MediaPipe?.drawConnectors
          ) {
            console.log("ğŸ‰ All MediaPipe objects loaded successfully");
            resolve();
          } else if (retries < maxRetries) {
            retries++;
            console.log(
              `â³ Waiting for MediaPipe objects... (${retries}/${maxRetries})`
            );
            setTimeout(checkMediaPipe, 100);
          } else {
            console.error(
              "âŒ MediaPipe objects not found after loading scripts"
            );
            reject(new Error("MediaPipe objects not available after loading"));
          }
        };

        checkMediaPipe();
      } catch (error) {
        reject(error);
      }
    };

    loadSequentially();
  });
};

// Holistic ì´ˆê¸°í™” í•¨ìˆ˜ë¥¼ ì»´í¬ë„ŒíŠ¸ ì™¸ë¶€ë¡œ ë¶„ë¦¬
const initializeHolistic = async (
  onResults: (results: any) => void
): Promise<any> => {
  try {
    if (!window.MediaPipe?.Holistic) {
      throw new Error("MediaPipe.Holistic not available");
    }

    console.log("ğŸš€ Initializing Holistic...");

    const holistic = new window.MediaPipe.Holistic({
      locateFile: (file: string) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/holistic@0.5.1635989137/${file}`;
      },
    });

    holistic.setOptions({
      selfieMode: true,
      modelComplexity: 1,
      smoothLandmarks: true,
      enableSegmentation: false, // í•„ìš”ì—†ìœ¼ë©´ ë„ê¸°
      smoothSegmentation: false,
      refineFaceLandmarks: false, // ì–¼êµ´ í•„ìš”ì—†ìœ¼ë©´ ë„ê¸°
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.5,
    });

    holistic.onResults(onResults);

    console.log("âœ… Holistic initialized successfully");
    return holistic;
  } catch (error) {
    console.error(`âŒ Holistic initialization error: ${error}`);
    throw error;
  }
};
