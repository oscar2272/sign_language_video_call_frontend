import React, { useEffect, useRef, useState } from "react";
import { Button } from "~/common/components/ui/button";
import { useOutletContext, useNavigate } from "react-router";
import type { UserProfile } from "~/features/profiles/type";
import type { Route } from "./+types/call-page";

// MediaPipe íƒ€ì… ì •ì˜
declare global {
  interface Window {
    Hands: any;
    Camera: any;
    drawConnectors: any;
    drawLandmarks: any;
    HAND_CONNECTIONS: any;
  }
}

export const loader = async ({ params }: Route.LoaderArgs) => {
  console.log("roomId:", params.id);
  return { roomId: params.id || null };
};

const BASE_URL = import.meta.env.VITE_API_BASE_URL;
const CALL_API_URL = `${BASE_URL}/api/calls`;
const WS_BASE_URL =
  import.meta.env.VITE_WS_BASE_URL ?? `ws://${window.location.hostname}:8000`;
const AI_WS_URL = `${WS_BASE_URL}/ai`;

export default function CallPage({ loaderData }: Route.ComponentProps) {
  const { roomId } = loaderData;
  const navigate = useNavigate();
  const { user, token } = useOutletContext<{
    user: UserProfile;
    token: string;
  }>();

  // ê¸°ì¡´ ìƒíƒœë“¤
  const [localStream, setLocalStream] = useState<MediaStream | null>(null);
  const [remoteStream, setRemoteStream] = useState<MediaStream | null>(null);
  const [callStatus, setCallStatus] = useState<
    "calling" | "connecting" | "connected" | "rejected" | "ended"
  >("calling");
  const [isCameraOn, setIsCameraOn] = useState(true);
  const [isMicOn, setIsMicOn] = useState(true);
  const [connectionTime, setConnectionTime] = useState(0);
  const [debugInfo, setDebugInfo] = useState<string[]>([]);

  // AI ê¸°ëŠ¥ ìƒíƒœë“¤ - ì¤‘ìš”: ì´ˆê¸°ê°’ê³¼ ë¡œë”© ìƒíƒœ ë¶„ë¦¬
  const [isAIEnabled, setIsAIEnabled] = useState(false);
  const [aiStatus, setAiStatus] = useState<
    "disconnected" | "connecting" | "connected"
  >("disconnected");
  const [handLandmarks, setHandLandmarks] = useState<any[]>([]);
  const [mediaPipeLoaded, setMediaPipeLoaded] = useState(false);
  const [isMediaPipeInitializing, setIsMediaPipeInitializing] = useState(false);

  // í”„ë ˆì„ ë²„í¼ ìƒíƒœë“¤
  const [frameBuffer, setFrameBuffer] = useState<any[][]>([]);
  const frameBufferRef = useRef<any[][]>([]);
  const [bufferCount, setBufferCount] = useState(0);
  const FRAME_BUFFER_SIZE = 10; // 10í”„ë ˆì„ ëª¨ì•„ì„œ ì „ì†¡
  const [lastFrameTime, setLastFrameTime] = useState(0); // í”„ë ˆì„ ì „ì†¡ ì œì–´
  const FRAME_SEND_INTERVAL = 100; // 100msë§ˆë‹¤ ì „ì†¡ (ì´ˆë‹¹ 10íšŒ)

  // ìë§‰ ìƒíƒœë“¤ (ê¸°ì¡´)
  const [currentSubtitle, setCurrentSubtitle] = useState<string>("");
  const [subtitleHistory, setSubtitleHistory] = useState<
    Array<{ text: string; timestamp: number; score?: number }>
  >([]);
  const [showSubtitleHistory, setShowSubtitleHistory] = useState(false);

  // ìë§‰ ì•ˆì •í™” ê´€ë ¨ ìƒˆë¡œìš´ ìƒíƒœë“¤
  const [subtitleQueue, setSubtitleQueue] = useState<
    Array<{
      text: string;
      timestamp: number;
      confidence?: number;
    }>
  >([]);
  const [displayedSubtitle, setDisplayedSubtitle] = useState<string>("");
  const [lastSubtitleUpdate, setLastSubtitleUpdate] = useState<number>(0);

  // Refs
  const localVideoRef = useRef<HTMLVideoElement>(null);
  const remoteVideoRef = useRef<HTMLVideoElement>(null);
  const wsRef = useRef<WebSocket | null>(null);
  const aiWsRef = useRef<WebSocket | null>(null);
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const connectionTimeRef = useRef<NodeJS.Timeout | null>(null);
  const pendingCandidatesRef = useRef<RTCIceCandidateInit[]>([]);
  const localStreamRef = useRef<MediaStream | null>(null);

  // MediaPipe refs
  const handsRef = useRef<any>(null);
  const cameraRef = useRef<any>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const frameIntervalRef = useRef<NodeJS.Timeout | null>(null);

  // ìë§‰ ì•ˆì •í™” ê´€ë ¨ refs
  const subtitleTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const subtitleStabilityRef = useRef<NodeJS.Timeout | null>(null);

  // í˜„ì¬ AI í™œì„± ìƒíƒœë¥¼ refë¡œë„ ê´€ë¦¬ (ì½œë°±ì—ì„œ ìµœì‹  ìƒíƒœ ì°¸ì¡°)
  const isAIEnabledRef = useRef(false);

  // ìë§‰ ì•ˆì •í™” ì„¤ì •
  const SUBTITLE_CONFIG = {
    MIN_DISPLAY_TIME: 2000, // ìµœì†Œ 2ì´ˆê°„ í‘œì‹œ
    STABILITY_DELAY: 500, // 0.5ì´ˆ ì•ˆì •í™” ì§€ì—°
    MAX_DISPLAY_TIME: 5000, // ìµœëŒ€ 5ì´ˆê°„ í‘œì‹œ
    MIN_CONFIDENCE: 0.6, // ìµœì†Œ ì‹ ë¢°ë„ (60%)
    DUPLICATE_THRESHOLD: 0.8, // ì¤‘ë³µ íŒì • ì„ê³„ê°’ (80% ìœ ì‚¬)
  };

  // ë””ë²„ê·¸ ë¡œê·¸ í•¨ìˆ˜
  const addDebugLog = (message: string) => {
    console.log(`[CallPage] ${message}`);
    setDebugInfo((prev) => [
      ...prev.slice(-8),
      `${new Date().toLocaleTimeString()}: ${message}`,
    ]);
  };

  // í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œë§Œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜ë“¤ì„ ìœ„í•œ í—¬í¼
  const isClient = typeof window !== "undefined";

  // ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
  const calculateSimilarity = (str1: string, str2: string): number => {
    if (!str1 || !str2) return 0;

    const longer = str1.length > str2.length ? str1 : str2;
    const shorter = str1.length > str2.length ? str2 : str1;

    if (longer.length === 0) return 1.0;

    const distance = levenshteinDistance(longer, shorter);
    return (longer.length - distance) / longer.length;
  };

  // ë ˆë²¤ìŠˆíƒ€ì¸ ê±°ë¦¬ ê³„ì‚°
  const levenshteinDistance = (str1: string, str2: string): number => {
    const matrix = [];

    for (let i = 0; i <= str2.length; i++) {
      matrix[i] = [i];
    }

    for (let j = 0; j <= str1.length; j++) {
      matrix[0][j] = j;
    }

    for (let i = 1; i <= str2.length; i++) {
      for (let j = 1; j <= str1.length; j++) {
        if (str2.charAt(i - 1) === str1.charAt(j - 1)) {
          matrix[i][j] = matrix[i - 1][j - 1];
        } else {
          matrix[i][j] = Math.min(
            matrix[i - 1][j - 1] + 1,
            matrix[i][j - 1] + 1,
            matrix[i - 1][j] + 1
          );
        }
      }
    }

    return matrix[str2.length][str1.length];
  };

  // ìë§‰ í•„í„°ë§ ë° ì•ˆì •í™” í•¨ìˆ˜
  const processSubtitle = (newText: string, confidence: number = 1.0) => {
    const now = Date.now();

    // ì‹ ë¢°ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë¬´ì‹œ
    if (confidence < SUBTITLE_CONFIG.MIN_CONFIDENCE) {
      addDebugLog(`ìë§‰ ì‹ ë¢°ë„ ë‚®ìŒ: ${(confidence * 100).toFixed(1)}%`);
      return;
    }

    // í˜„ì¬ í‘œì‹œëœ ìë§‰ê³¼ ìœ ì‚¬ë„ í™•ì¸
    if (displayedSubtitle) {
      const similarity = calculateSimilarity(
        displayedSubtitle.toLowerCase(),
        newText.toLowerCase()
      );
      if (similarity > SUBTITLE_CONFIG.DUPLICATE_THRESHOLD) {
        addDebugLog(`ìœ ì‚¬í•œ ìë§‰ ë¬´ì‹œ: ${(similarity * 100).toFixed(1)}% ìœ ì‚¬`);
        return;
      }
    }

    // ìë§‰ íì— ì¶”ê°€
    const newSubtitle = {
      text: newText,
      timestamp: now,
      confidence: confidence,
    };

    setSubtitleQueue((prev) => [...prev.slice(-4), newSubtitle]); // ìµœëŒ€ 5ê°œ ìœ ì§€

    // ê¸°ì¡´ ì•ˆì •í™” íƒ€ì´ë¨¸ í´ë¦¬ì–´
    if (subtitleStabilityRef.current) {
      clearTimeout(subtitleStabilityRef.current);
    }

    // ì•ˆì •í™” ì§€ì—° í›„ ìë§‰ ì—…ë°ì´íŠ¸
    subtitleStabilityRef.current = setTimeout(() => {
      updateDisplayedSubtitle(newSubtitle);
    }, SUBTITLE_CONFIG.STABILITY_DELAY);

    addDebugLog(
      `ìë§‰ í ì¶”ê°€: "${newText}" (ì‹ ë¢°ë„: ${(confidence * 100).toFixed(1)}%)`
    );
  };

  // í‘œì‹œí•  ìë§‰ ì—…ë°ì´íŠ¸
  const updateDisplayedSubtitle = (subtitle: {
    text: string;
    timestamp: number;
    confidence?: number;
  }) => {
    const now = Date.now();

    // ìˆ˜ì–´ ë™ì‘ ì¤‘ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ìµœì†Œ ì‹œê°„ ì œí•œ ì™„í™”
    if (now - lastSubtitleUpdate < SUBTITLE_CONFIG.MIN_DISPLAY_TIME) {
      // ì‹ ë¢°ë„ê°€ ë†’ê±°ë‚˜ ë‚´ìš©ì´ ë§ì´ ë‹¤ë¥´ë©´ ë°”ë¡œ ì—…ë°ì´íŠ¸ í—ˆìš©
      const currentConfidence = subtitle.confidence || 1.0;
      if (currentConfidence < 0.8 && displayedSubtitle) {
        addDebugLog(
          `ìë§‰ ì—…ë°ì´íŠ¸ ì§€ì—°: ì‹ ë¢°ë„ ë‚®ìŒ ${(currentConfidence * 100).toFixed(1)}%`
        );
        return;
      }
    }

    setDisplayedSubtitle(subtitle.text);
    setCurrentSubtitle(subtitle.text);
    setLastSubtitleUpdate(now);

    // ìë§‰ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    setSubtitleHistory((prev) => [
      ...prev,
      {
        text: subtitle.text,
        timestamp: subtitle.timestamp,
        score: subtitle.confidence,
      },
    ]);

    addDebugLog(`ìë§‰ í‘œì‹œ: "${subtitle.text}"`);

    // ê¸°ì¡´ íƒ€ì´ë¨¸ í´ë¦¬ì–´
    if (subtitleTimeoutRef.current) {
      clearTimeout(subtitleTimeoutRef.current);
    }

    // ìë§‰ ìë™ ì œê±° íƒ€ì´ë¨¸ (ìˆ˜ì–´ ë™ì‘ ì¤‘ì—ëŠ” ë” ì§§ê²Œ)
    subtitleTimeoutRef.current = setTimeout(() => {
      setDisplayedSubtitle("");
      setCurrentSubtitle("");
      addDebugLog(`ìë§‰ ìë™ ì œê±°`);
    }, SUBTITLE_CONFIG.MAX_DISPLAY_TIME);
  };

  // ìˆ˜ë™ ìë§‰ ì œê±° í•¨ìˆ˜
  const clearCurrentSubtitle = () => {
    setDisplayedSubtitle("");
    setCurrentSubtitle("");
    setLastSubtitleUpdate(0);

    if (subtitleTimeoutRef.current) {
      clearTimeout(subtitleTimeoutRef.current);
      subtitleTimeoutRef.current = null;
    }

    if (subtitleStabilityRef.current) {
      clearTimeout(subtitleStabilityRef.current);
      subtitleStabilityRef.current = null;
    }

    addDebugLog(`ìë§‰ ìˆ˜ë™ ì œê±°`);
  };

  // í”„ë ˆì„ ì‹œí€€ìŠ¤ ì „ì†¡ í•¨ìˆ˜
  const sendFrameSequence = (frameSequence: any[][]) => {
    if (
      !isAIEnabledRef.current ||
      !aiWsRef.current ||
      aiWsRef.current.readyState !== WebSocket.OPEN
    ) {
      return;
    }

    const message = {
      type: "hand_landmarks_sequence",
      room_id: roomId,
      frame_sequence: frameSequence, // 10í”„ë ˆì„ x 21ì¢Œí‘œ ë°°ì—´
      timestamp: Date.now(),
      test_id: Math.random().toString(36).substr(2, 9),
    };

    try {
      const messageStr = JSON.stringify(message);
      aiWsRef.current.send(messageStr);
      addDebugLog(`10í”„ë ˆì„ ì‹œí€€ìŠ¤ ì „ì†¡ ì„±ê³µ! [${message.test_id}]`);
    } catch (error) {
      addDebugLog(`ì‹œí€€ìŠ¤ ì „ì†¡ ì‹¤íŒ¨: ${error}`);
    }
  };

  // í”„ë ˆì„ ë²„í¼ì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
  const addToFrameBuffer = (handData: Array<{ x: number; y: number }>) => {
    const now = Date.now();

    // í”„ë ˆì„ ì „ì†¡ ë¹ˆë„ ì œì–´ (100ms ê°„ê²©)
    if (now - lastFrameTime < FRAME_SEND_INTERVAL) {
      return; // ë„ˆë¬´ ë¹¨ë¦¬ ì˜¤ëŠ” í”„ë ˆì„ì€ ë¬´ì‹œ
    }

    setLastFrameTime(now);

    // 21ê°œ ì¢Œí‘œê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ íŒ¨ë”©
    const paddedHandData = [];
    for (let i = 0; i < 21; i++) {
      if (i < handData.length) {
        paddedHandData.push([handData[i].x, handData[i].y]);
      } else {
        paddedHandData.push([0, 0]); // ë¹ˆ ì¢Œí‘œëŠ” 0ìœ¼ë¡œ íŒ¨ë”©
      }
    }

    // ìƒˆë¡œìš´ í”„ë ˆì„ì„ ë²„í¼ì— ì¶”ê°€
    const newBuffer = [...frameBufferRef.current, paddedHandData];

    if (newBuffer.length >= FRAME_BUFFER_SIZE) {
      // 10í”„ë ˆì„ì´ ëª¨ì´ë©´ ì „ì†¡
      const frameSequence = newBuffer.slice(-FRAME_BUFFER_SIZE); // ìµœê·¼ 10í”„ë ˆì„ë§Œ ì‚¬ìš©
      sendFrameSequence(frameSequence);

      // ë²„í¼ ì™„ì „ ì´ˆê¸°í™” (ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ ì œê±°)
      frameBufferRef.current = [];
      setFrameBuffer([]);
      setBufferCount(0);
    } else {
      // ë²„í¼ì— ì¶”ê°€ë§Œ
      frameBufferRef.current = newBuffer;
      setFrameBuffer(newBuffer);
      setBufferCount(newBuffer.length);
    }
  };

  // MediaPipe ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ
  const loadMediaPipeScripts = (): Promise<void> => {
    return new Promise((resolve, reject) => {
      if (!isClient) {
        reject(new Error("Not in client environment"));
        return;
      }

      if (window.Hands && window.Camera && window.drawConnectors) {
        addDebugLog("MediaPipe already loaded");
        setMediaPipeLoaded(true);
        resolve();
        return;
      }

      addDebugLog("Loading MediaPipe scripts...");

      const scripts = [
        "https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3.1675466862/camera_utils.min.js",
        "https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3.1675466124/drawing_utils.min.js",
        "https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675469240/hands.min.js",
      ];

      let loadedCount = 0;

      scripts.forEach((src, index) => {
        const script = document.createElement("script");
        script.src = src;
        script.async = true;

        script.onload = () => {
          loadedCount++;
          addDebugLog(`Script ${index + 1}/3 loaded: ${src.split("/").pop()}`);

          if (loadedCount === scripts.length) {
            // ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ê°€ ë¡œë“œë˜ë©´ ì ì‹œ ê¸°ë‹¤ë¦° í›„ í™•ì¸
            setTimeout(() => {
              if (window.Hands && window.Camera && window.drawConnectors) {
                addDebugLog("All MediaPipe scripts loaded successfully");
                setMediaPipeLoaded(true);
                resolve();
              } else {
                addDebugLog("Scripts loaded but objects not available");
                reject(new Error("MediaPipe objects not available"));
              }
            }, 500);
          }
        };

        script.onerror = () => {
          addDebugLog(`Failed to load script: ${src}`);
          reject(new Error(`Failed to load ${src}`));
        };

        document.head.appendChild(script);
      });
    });
  };

  // Hands ëª¨ë¸ ì´ˆê¸°í™”
  const initHands = () => {
    try {
      if (!isClient || !window.Hands) {
        addDebugLog("window.Hands not available");
        return;
      }

      const hands = new window.Hands({
        locateFile: (file: string) => {
          return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1675469240/${file}`;
        },
      });

      hands.setOptions({
        maxNumHands: 2,
        modelComplexity: 1,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5,
      });

      hands.onResults(onHandsResults);
      handsRef.current = hands;

      addDebugLog("MediaPipe Hands initialized successfully");
    } catch (error) {
      addDebugLog(`Hands initialization error: ${error}`);
    }
  };

  // ì† ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬ - 10í”„ë ˆì„ ë²„í¼ë§
  const onHandsResults = (results: any) => {
    if (!results.multiHandLandmarks) {
      setHandLandmarks([]);
      // ì†ì´ ì¸ì‹ë˜ì§€ ì•Šì•„ë„ ë¹ˆ í”„ë ˆì„ìœ¼ë¡œ ì²˜ë¦¬ (ì—°ì†ì„± ìœ ì§€)
      if (isAIEnabledRef.current) {
        addToFrameBuffer([]);
      }
      return;
    }

    const landmarks: any[] = [];
    for (let i = 0; i < results.multiHandLandmarks.length; i++) {
      const handLandmarks = results.multiHandLandmarks[i];
      const handData: Array<{ x: number; y: number }> = [];

      for (let j = 0; j < handLandmarks.length; j++) {
        handData.push({
          x: handLandmarks[j].x,
          y: handLandmarks[j].y,
        });
      }
      landmarks.push(handData);
    }

    setHandLandmarks(landmarks);

    // ì²« ë²ˆì§¸ ì†ë§Œ ì‚¬ìš© (ëª¨ë¸ì´ í•œ ì†ë§Œ ì²˜ë¦¬)
    const primaryHand = landmarks.length > 0 ? landmarks[0] : [];

    if (isAIEnabledRef.current) {
      addToFrameBuffer(primaryHand);
    }
  };

  // MediaPipe ì¹´ë©”ë¼ ì‹œì‘
  const startMediaPipeCamera = async () => {
    if (!isClient || !localVideoRef.current || !handsRef.current) {
      addDebugLog("Video element or Hands not ready");
      return;
    }

    try {
      if (window.Camera) {
        const camera = new window.Camera(localVideoRef.current, {
          onFrame: async () => {
            if (handsRef.current && localVideoRef.current) {
              await handsRef.current.send({ image: localVideoRef.current });
            }
          },
          width: 640,
          height: 480,
        });

        cameraRef.current = camera;
        camera.start();
        addDebugLog("MediaPipe camera started");
      } else {
        addDebugLog("Camera utility not available");
      }
    } catch (error) {
      addDebugLog(`Camera start error: ${error}`);
    }
  };

  // MediaPipe ì´ˆê¸°í™”
  const initializeMediaPipe = async () => {
    if (!isClient) return;

    try {
      setIsMediaPipeInitializing(true);
      addDebugLog("Initializing MediaPipe...");

      await loadMediaPipeScripts();
      initHands();

      // ë¹„ë””ì˜¤ê°€ ì¤€ë¹„ë˜ë©´ ì¹´ë©”ë¼ ì‹œì‘
      if (localVideoRef.current) {
        await startMediaPipeCamera();
      }

      setIsMediaPipeInitializing(false);
    } catch (error) {
      addDebugLog(`MediaPipe initialization failed: ${error}`);
      setIsMediaPipeInitializing(false);
    }
  };

  // AI WebSocket ì—°ê²°
  const connectAIWebSocket = () => {
    if (!isClient) return;

    try {
      addDebugLog("AI WebSocket ì—°ê²° ì‹œë„ ì¤‘...");
      setAiStatus("connecting");

      const wsUrl = `${AI_WS_URL}?role=client&room=${roomId}`;
      addDebugLog(`ì—°ê²° URL: ${wsUrl}`);

      const aiWs = new WebSocket(wsUrl);

      aiWs.onopen = () => {
        addDebugLog("AI WebSocket ì—°ê²° ì„±ê³µ!");
        setAiStatus("connected");

        // ì—°ê²° ì¦‰ì‹œ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
        const testMessage = {
          type: "connection_test",
          room_id: roomId,
          timestamp: Date.now(),
          message: "í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²° í…ŒìŠ¤íŠ¸",
        };

        try {
          aiWs.send(JSON.stringify(testMessage));
          addDebugLog("ì—°ê²° í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ");
        } catch (error) {
          addDebugLog(`í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: ${error}`);
        }
      };

      aiWs.onmessage = (event) => {
        addDebugLog(`ì„œë²„ ì‘ë‹µ ë°›ìŒ: ${event.data}`);
        try {
          const data = JSON.parse(event.data);

          if (data.type === "caption") {
            // ìƒˆë¡œìš´ ìë§‰ ì²˜ë¦¬ í•¨ìˆ˜ ì‚¬ìš©
            processSubtitle(data.text, data.confidence || 1.0);
          }
        } catch (error) {
          addDebugLog(`ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜: ${error}`);
        }
      };

      aiWs.onclose = (event) => {
        addDebugLog(
          `AI WebSocket ì—°ê²° ì¢…ë£Œ: code=${event.code}, reason=${event.reason}`
        );
        setAiStatus("disconnected");
      };

      aiWs.onerror = (error) => {
        addDebugLog(`AI WebSocket ì—ëŸ¬: ${error}`);
        setAiStatus("disconnected");
      };

      aiWsRef.current = aiWs;
    } catch (error) {
      addDebugLog(`WebSocket ìƒì„± ì‹¤íŒ¨: ${error}`);
      setAiStatus("disconnected");
    }
  };

  // AI ê¸°ëŠ¥ í† ê¸€
  const toggleAI = async () => {
    if (isAIEnabled) {
      // AI ë„ê¸°
      addDebugLog("AI ê¸°ëŠ¥ ë¹„í™œì„±í™” ì¤‘...");
      setIsAIEnabled(false);
      isAIEnabledRef.current = false; // refë„ ì—…ë°ì´íŠ¸

      // ë²„í¼ ì´ˆê¸°í™”
      frameBufferRef.current = [];
      setFrameBuffer([]);
      setBufferCount(0);

      if (aiWsRef.current) {
        aiWsRef.current.close();
        aiWsRef.current = null;
      }
      if (cameraRef.current) {
        cameraRef.current.stop();
        cameraRef.current = null;
      }
      setAiStatus("disconnected");
      addDebugLog("AI feature disabled");
    } else {
      // AI ì¼œê¸°
      addDebugLog("AI ê¸°ëŠ¥ í™œì„±í™” ì¤‘...");
      setIsAIEnabled(true);
      isAIEnabledRef.current = true; // refë„ ì—…ë°ì´íŠ¸

      // ë²„í¼ ì´ˆê¸°í™”
      frameBufferRef.current = [];
      setFrameBuffer([]);
      setBufferCount(0);

      // MediaPipe ì´ˆê¸°í™” (ì•„ì§ ì•ˆ ëìœ¼ë©´)
      if (!mediaPipeLoaded) {
        await initializeMediaPipe();
      } else if (!cameraRef.current && handsRef.current) {
        await startMediaPipeCamera();
      }

      // AI WebSocket ì—°ê²°
      connectAIWebSocket();

      addDebugLog("AI feature enabled");
    }
  };

  // isAIEnabled ìƒíƒœê°€ ë³€ê²½ë  ë•Œë§ˆë‹¤ ref ë™ê¸°í™”
  useEffect(() => {
    isAIEnabledRef.current = isAIEnabled;
    addDebugLog(`AI ìƒíƒœ ë™ê¸°í™”: ${isAIEnabled}`);
  }, [isAIEnabled]);

  // WebRTC ì„¤ì • (ê¸°ì¡´ ì½”ë“œ)
  const createPeerConnection = () => {
    addDebugLog("Creating peer connection...");

    const pc = new RTCPeerConnection({
      iceServers: [
        { urls: "stun:stun.l.google.com:19302" },
        { urls: "stun:stun1.l.google.com:19302" },
      ],
    });

    pc.onicecandidate = (event) => {
      if (event.candidate && wsRef.current?.readyState === WebSocket.OPEN) {
        addDebugLog("Sending ICE candidate");
        wsRef.current.send(
          JSON.stringify({
            type: "ice",
            candidate: event.candidate,
          })
        );
      } else if (!event.candidate) {
        addDebugLog("ICE gathering complete");
      }
    };

    pc.ontrack = (event) => {
      addDebugLog("Remote track received");
      setRemoteStream(event.streams[0]);
    };

    pc.onconnectionstatechange = () => {
      const state = pc.connectionState;
      addDebugLog(`Connection state changed: ${state}`);

      if (state === "connected") {
        setCallStatus("connected");
        startConnectionTimer();
      } else if (state === "failed" || state === "closed") {
        addDebugLog("Connection failed or closed, ending call");
        endCall();
      }
    };

    pc.onicegatheringstatechange = () => {
      addDebugLog(`ICE gathering state: ${pc.iceGatheringState}`);
    };

    pc.onsignalingstatechange = () => {
      addDebugLog(`Signaling state: ${pc.signalingState}`);
    };

    return pc;
  };

  // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” (ê¸°ì¡´ ì½”ë“œ)
  const initializeMedia = async (): Promise<MediaStream | null> => {
    if (!isClient) return null;

    try {
      addDebugLog("Requesting media access...");
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 1280, height: 720 },
        audio: true,
      });

      localStreamRef.current = stream;
      setLocalStream(stream);
      addDebugLog("Media access granted");

      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;

        // ë¹„ë””ì˜¤ê°€ ë¡œë“œë˜ë©´ MediaPipe ì¤€ë¹„
        localVideoRef.current.onloadedmetadata = () => {
          if (isAIEnabled && mediaPipeLoaded && handsRef.current) {
            startMediaPipeCamera();
          }
        };
      }

      return stream;
    } catch (error) {
      addDebugLog(`Media access error: ${error}`);
      alert("ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
      return null;
    }
  };

  // django WebSocket ì—°ê²° (ê¸°ì¡´ ì½”ë“œ)
  const connectWebSocket = (stream: MediaStream) => {
    if (!isClient) return null;

    addDebugLog("Connecting to WebSocket...");
    const ws = new WebSocket(
      `${WS_BASE_URL}/ws/call/${roomId}/?user_id=${user.id}`
    );

    ws.onopen = () => {
      addDebugLog("WebSocket connected - ready for signaling");
      setCallStatus("connecting");
    };

    ws.onmessage = async (event) => {
      const data = JSON.parse(event.data);
      addDebugLog(`WebSocket message: ${data.type}`);

      switch (data.type) {
        case "user_joined":
          addDebugLog("User joined, creating offer");
          setCallStatus("connecting");
          setTimeout(() => createOffer(stream), 500);
          break;

        case "offer":
          addDebugLog("Received offer, handling...");
          await handleOffer(data.offer, stream);
          break;

        case "answer":
          addDebugLog("Received answer, handling...");
          await handleAnswer(data.answer);
          break;

        case "ice":
          addDebugLog("Received ICE candidate");
          await handleIceCandidate(data.candidate);
          break;

        case "end_call":
          setCallStatus("ended");
          cleanup();
          setTimeout(() => navigate("/friends"), 2000);
          break;
      }
    };

    ws.onclose = () => {
      addDebugLog("WebSocket disconnected");
    };

    ws.onerror = (error) => {
      addDebugLog(`WebSocket error: ${error}`);
    };

    return ws;
  };

  // Offer ìƒì„± (ê¸°ì¡´ ì½”ë“œ)
  const createOffer = async (stream: MediaStream) => {
    addDebugLog("Creating offer...");

    if (!stream) {
      addDebugLog("Stream not provided to createOffer");
      return;
    }

    addDebugLog(`Stream ready with ${stream.getTracks().length} tracks`);

    const pc = createPeerConnection();
    pcRef.current = pc;

    stream.getTracks().forEach((track) => {
      addDebugLog(`Adding ${track.kind} track to peer connection`);
      pc.addTrack(track, stream);
    });

    try {
      const offer = await pc.createOffer({
        offerToReceiveAudio: true,
        offerToReceiveVideo: true,
      });

      await pc.setLocalDescription(offer);
      addDebugLog("Offer created and set as local description");

      if (wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.send(
          JSON.stringify({
            type: "offer",
            offer: offer,
          })
        );
        addDebugLog("Offer sent via WebSocket");
      } else {
        addDebugLog("WebSocket not ready, cannot send offer");
      }
    } catch (error) {
      addDebugLog(`Error creating offer: ${error}`);
    }
  };

  // Offer ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
  const handleOffer = async (
    offer: RTCSessionDescriptionInit,
    stream: MediaStream
  ) => {
    addDebugLog("Handling offer...");

    if (!stream) {
      addDebugLog("Stream not available for handling offer");
      return;
    }

    const pc = createPeerConnection();
    pcRef.current = pc;

    stream.getTracks().forEach((track) => {
      addDebugLog(`Adding ${track.kind} track to peer connection`);
      pc.addTrack(track, stream);
    });

    try {
      await pc.setRemoteDescription(new RTCSessionDescription(offer));
      addDebugLog("Remote description (offer) set");

      for (const candidate of pendingCandidatesRef.current) {
        await pc.addIceCandidate(new RTCIceCandidate(candidate));
        addDebugLog("Added pending ICE candidate");
      }
      pendingCandidatesRef.current = [];

      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);
      addDebugLog("Answer created and set as local description");

      if (wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.send(
          JSON.stringify({
            type: "answer",
            answer: answer,
          })
        );
        addDebugLog("Answer sent via WebSocket");
      }
    } catch (error) {
      addDebugLog(`Error handling offer: ${error}`);
    }
  };

  // Answer ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
  const handleAnswer = async (answer: RTCSessionDescriptionInit) => {
    addDebugLog("Handling answer...");

    if (!pcRef.current) {
      addDebugLog("PeerConnection not ready for handling answer");
      return;
    }

    try {
      await pcRef.current.setRemoteDescription(
        new RTCSessionDescription(answer)
      );
      addDebugLog("Remote description (answer) set successfully");

      for (const candidate of pendingCandidatesRef.current) {
        await pcRef.current.addIceCandidate(new RTCIceCandidate(candidate));
        addDebugLog("Added pending ICE candidate");
      }
      pendingCandidatesRef.current = [];
    } catch (error) {
      addDebugLog(`Error handling answer: ${error}`);
    }
  };

  // ICE Candidate ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
  const handleIceCandidate = async (candidate: RTCIceCandidateInit) => {
    if (!pcRef.current) {
      addDebugLog("PeerConnection not ready, storing ICE candidate");
      pendingCandidatesRef.current.push(candidate);
      return;
    }

    if (pcRef.current.remoteDescription) {
      try {
        await pcRef.current.addIceCandidate(new RTCIceCandidate(candidate));
        addDebugLog("ICE candidate added successfully");
      } catch (error) {
        addDebugLog(`Error adding ICE candidate: ${error}`);
      }
    } else {
      addDebugLog("Remote description not set, storing ICE candidate");
      pendingCandidatesRef.current.push(candidate);
    }
  };

  // ì—°ê²° ì‹œê°„ íƒ€ì´ë¨¸ (ê¸°ì¡´ ì½”ë“œ)
  const startConnectionTimer = () => {
    connectionTimeRef.current = setInterval(() => {
      setConnectionTime((prev) => prev + 1);
    }, 1000);
  };

  // í†µí™” ì¢…ë£Œ (ê¸°ì¡´ ì½”ë“œ)
  const endCall = async () => {
    addDebugLog("Ending call...");

    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: "end_call" }));
    }

    setCallStatus("ended");
    cleanup();

    if (isClient) {
      try {
        await fetch(`${CALL_API_URL}/end/`, {
          method: "POST",
          headers: {
            Authorization: `Bearer ${token}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({ room_id: roomId }),
        });
      } catch (err) {
        addDebugLog(`Failed to end call: ${err}`);
      }
    }

    setTimeout(() => navigate("/friends"), 2000);
  };

  // ì¹´ë©”ë¼ í† ê¸€ (ê¸°ì¡´ ì½”ë“œ)
  const toggleCamera = () => {
    const stream = localStreamRef.current;
    if (stream) {
      const videoTrack = stream.getVideoTracks()[0];
      if (videoTrack) {
        videoTrack.enabled = !videoTrack.enabled;
        setIsCameraOn(videoTrack.enabled);
        addDebugLog(`Camera ${videoTrack.enabled ? "enabled" : "disabled"}`);
      }
    }
  };

  // ë§ˆì´í¬ í† ê¸€ (ê¸°ì¡´ ì½”ë“œ)
  const toggleMic = () => {
    const stream = localStreamRef.current;
    if (stream) {
      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = !audioTrack.enabled;
        setIsMicOn(audioTrack.enabled);
        addDebugLog(`Mic ${audioTrack.enabled ? "enabled" : "disabled"}`);
      }
    }
  };

  // ì •ë¦¬ í•¨ìˆ˜ (ìˆ˜ì •ë¨)
  const cleanup = () => {
    addDebugLog("Cleaning up resources...");

    if (connectionTimeRef.current) {
      clearInterval(connectionTimeRef.current);
    }

    if (frameIntervalRef.current) {
      clearInterval(frameIntervalRef.current);
      frameIntervalRef.current = null;
    }

    if (cameraRef.current) {
      cameraRef.current.stop();
      cameraRef.current = null;
    }

    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach((track) => track.stop());
    }

    if (pcRef.current) {
      pcRef.current.close();
    }

    if (wsRef.current) {
      wsRef.current.close();
    }

    if (aiWsRef.current) {
      aiWsRef.current.close();
    }

    // ìë§‰ ê´€ë ¨ íƒ€ì´ë¨¸ í´ë¦¬ì–´ ì¶”ê°€
    if (subtitleTimeoutRef.current) {
      clearTimeout(subtitleTimeoutRef.current);
      subtitleTimeoutRef.current = null;
    }

    if (subtitleStabilityRef.current) {
      clearTimeout(subtitleStabilityRef.current);
      subtitleStabilityRef.current = null;
    }

    // AI ìƒíƒœ ì´ˆê¸°í™”
    setIsAIEnabled(false);
    isAIEnabledRef.current = false;
    setAiStatus("disconnected");

    // ë²„í¼ ì´ˆê¸°í™”
    frameBufferRef.current = [];
    setFrameBuffer([]);
    setBufferCount(0);

    // ìë§‰ ìƒíƒœ ì´ˆê¸°í™”
    setSubtitleQueue([]);
    setDisplayedSubtitle("");
    setCurrentSubtitle("");
    setLastSubtitleUpdate(0);
  };

  // ì‹œê°„ í¬ë§·íŒ… (ê¸°ì¡´ ì½”ë“œ)
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, "0")}:${secs.toString().padStart(2, "0")}`;
  };

  // ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” - í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œë§Œ ì‹¤í–‰
  useEffect(() => {
    if (!isClient || !roomId) {
      if (!roomId) navigate("/friends");
      return;
    }

    addDebugLog("Initializing CallPage");

    const init = async () => {
      const stream = await initializeMedia();
      if (!stream) return;

      addDebugLog("Media stream ready, connecting WebSocket");
      wsRef.current = connectWebSocket(stream);
    };

    init();

    return cleanup;
  }, [roomId, navigate]);

  // ì›ê²© ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
  useEffect(() => {
    if (remoteStream && remoteVideoRef.current) {
      remoteVideoRef.current.srcObject = remoteStream;
      addDebugLog("Remote stream set to video element");
    }
  }, [remoteStream]);

  // ë²„íŠ¼ í…ìŠ¤íŠ¸ ê²°ì •
  const getAIButtonText = () => {
    if (isMediaPipeInitializing) return "ì´ˆê¸°í™”ì¤‘...";
    if (!mediaPipeLoaded && !isAIEnabled) return "AI ì¼œê¸°";
    if (isAIEnabled) return "AI ì¼œì§";
    return "AI ì¼œê¸°";
  };

  const getAIButtonIcon = () => {
    if (isMediaPipeInitializing) return "â³";
    if (!mediaPipeLoaded && !isAIEnabled) return "ğŸ”‡";
    if (isAIEnabled) return "ğŸ¤–";
    return "ğŸ”‡";
  };

  return (
    <div className="fixed inset-0 bg-gray-900 flex flex-col h-screen">
      {/* ìƒíƒœ í‘œì‹œ */}
      <div className="bg-gray-800 text-white p-3 text-center flex-shrink-0 min-h-[60px] flex items-center justify-between">
        <div className="flex-1 text-center">
          {callStatus === "calling" && (
            <span className="text-sm sm:text-base">ì „í™” ê±°ëŠ” ì¤‘...</span>
          )}
          {callStatus === "connecting" && (
            <span className="text-sm sm:text-base">ì—°ê²° ì¤‘...</span>
          )}
          {callStatus === "connected" && (
            <span className="text-sm sm:text-base">
              í†µí™” ì¤‘ - {formatTime(connectionTime)}
            </span>
          )}
          {callStatus === "rejected" && (
            <span className="text-sm sm:text-base">í†µí™”ê°€ ê±°ì ˆë˜ì—ˆìŠµë‹ˆë‹¤</span>
          )}
          {callStatus === "ended" && (
            <span className="text-sm sm:text-base">í†µí™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤</span>
          )}
        </div>

        {/* AI ìƒíƒœ í‘œì‹œ */}
        <div className="text-xs">
          <span
            className={`inline-block w-2 h-2 rounded-full mr-2 ${
              aiStatus === "connected"
                ? "bg-green-500"
                : aiStatus === "connecting"
                  ? "bg-yellow-500"
                  : "bg-red-500"
            }`}
          ></span>
          AI: {aiStatus}
          {mediaPipeLoaded && <span className="text-green-400 ml-1">âœ“MP</span>}
          {isMediaPipeInitializing && (
            <span className="text-yellow-400 ml-1">â³MP</span>
          )}
          {isAIEnabled && handLandmarks.length > 0 && (
            <span className="ml-2">ğŸ‘‹ {handLandmarks.length}</span>
          )}
        </div>
      </div>

      {/* ë””ë²„ê·¸ ì •ë³´ */}
      <div className="bg-red-900 text-white p-2 text-xs flex-shrink-0 max-h-32 overflow-y-auto">
        {debugInfo.map((info, index) => (
          <div
            key={index}
            className={index === debugInfo.length - 1 ? "text-yellow-300" : ""}
          >
            {info}
          </div>
        ))}
        {/* ì‹¤ì‹œê°„ ì¢Œí‘œ í‘œì‹œ */}
        {handLandmarks.length > 0 && (
          <div className="text-green-300 mt-1">
            ğŸ¤š Hands detected: {handLandmarks.length} | Points:{" "}
            {handLandmarks.reduce((sum, hand) => sum + hand.length, 0)} |
            {handLandmarks[0] && (
              <span>
                {" "}
                Sample: ({handLandmarks[0][0]?.x?.toFixed(3)},{" "}
                {handLandmarks[0][0]?.y?.toFixed(3)})
              </span>
            )}
          </div>
        )}
        {/* í˜„ì¬ ìƒíƒœ ìš”ì•½ */}
        <div className="text-blue-300 mt-1">
          ğŸ”§ State: AI={isAIEnabled ? "ON" : "OFF"} | MP=
          {mediaPipeLoaded ? "OK" : "NO"} | Init=
          {isMediaPipeInitializing ? "YES" : "NO"} | WS={aiStatus} | Buffer=
          {bufferCount}/{FRAME_BUFFER_SIZE}
        </div>
        {/* ìë§‰ ìƒíƒœ í‘œì‹œ ì¶”ê°€ */}
        <div className="text-purple-300 mt-1">
          ğŸ“ Subtitle: Queue={subtitleQueue.length} | Current="
          {displayedSubtitle || "none"}" | Last=
          {lastSubtitleUpdate
            ? new Date(lastSubtitleUpdate).toLocaleTimeString()
            : "never"}
        </div>
      </div>

      {/* ë¹„ë””ì˜¤ ì˜ì—­ */}
      <div
        className="flex-1 relative min-h-0"
        style={{ maxHeight: "calc(100vh - 200px)" }}
      >
        {/* ì›ê²© ë¹„ë””ì˜¤ (í° í™”ë©´) */}
        <video
          ref={remoteVideoRef}
          autoPlay
          playsInline
          className="w-full h-full object-cover"
          style={{ transform: "scaleX(-1)" }}
        />

        {/* ë¡œì»¬ ë¹„ë””ì˜¤ (ì‘ì€ í™”ë©´) */}
        <video
          ref={localVideoRef}
          autoPlay
          playsInline
          muted
          className={`absolute top-2 right-2 w-24 h-18 sm:w-32 sm:h-24 bg-gray-800 rounded-lg object-cover border-2 ${
            isAIEnabled ? "border-green-400" : "border-white"
          }`}
          style={{ transform: "scaleX(-1)" }}
        />

        {/* MediaPipe ì˜¤ë²„ë ˆì´ ìº”ë²„ìŠ¤ */}
        {isAIEnabled && (
          <canvas
            ref={canvasRef}
            className="absolute top-2 right-2 w-24 h-18 sm:w-32 sm:h-24 pointer-events-none"
            style={{ transform: "scaleX(-1)" }}
          />
        )}

        {/* í˜„ì¬ ìë§‰ í‘œì‹œ - displayedSubtitle ì‚¬ìš© */}
        {displayedSubtitle && (
          <div className="absolute bottom-20 left-1/2 transform -translate-x-1/2 bg-black bg-opacity-80 text-white px-4 py-2 rounded-lg text-center max-w-md">
            <div className="text-lg font-bold">{displayedSubtitle}</div>
          </div>
        )}

        {/* ìë§‰ ì œì–´ ë²„íŠ¼ë“¤ */}
        <div className="absolute bottom-2 left-2 flex gap-2">
          {/* ìë§‰ íˆìŠ¤í† ë¦¬ ë²„íŠ¼ */}
          {subtitleHistory.length > 0 && (
            <button
              onClick={() => setShowSubtitleHistory(!showSubtitleHistory)}
              className="bg-blue-600 hover:bg-blue-700 text-white px-3 py-1 rounded text-sm"
            >
              ìë§‰ ê¸°ë¡ ({subtitleHistory.length})
            </button>
          )}

          {/* í˜„ì¬ ìë§‰ ì œê±° ë²„íŠ¼ */}
          {displayedSubtitle && (
            <button
              onClick={clearCurrentSubtitle}
              className="bg-red-600 hover:bg-red-700 text-white px-3 py-1 rounded text-sm"
              title="í˜„ì¬ ìë§‰ ì œê±°"
            >
              ìë§‰ ì œê±°
            </button>
          )}

          {/* ìë§‰ í ìƒíƒœ í‘œì‹œ */}
          {subtitleQueue.length > 0 && (
            <div className="bg-yellow-600 text-white px-2 py-1 rounded text-xs">
              í: {subtitleQueue.length}
            </div>
          )}
        </div>

        {/* ìë§‰ íˆìŠ¤í† ë¦¬ íŒ¨ë„ */}
        {showSubtitleHistory && (
          <div className="absolute bottom-12 left-2 bg-black bg-opacity-90 text-white p-3 rounded-lg max-w-sm max-h-60 overflow-y-auto">
            <div className="flex justify-between items-center mb-2">
              <h3 className="text-sm font-bold">ë²ˆì—­ ê¸°ë¡</h3>
              <button
                onClick={() => setSubtitleHistory([])}
                className="text-red-400 hover:text-red-300 text-xs"
              >
                ì§€ìš°ê¸°
              </button>
            </div>
            <div className="space-y-1">
              {subtitleHistory
                .slice()
                .reverse()
                .map((item, index) => (
                  <div
                    key={index}
                    className="text-xs border-b border-gray-600 pb-1"
                  >
                    <div className="font-medium">{item.text}</div>
                    <div className="text-gray-400 text-xs">
                      {new Date(item.timestamp).toLocaleTimeString()}
                      {item.score !== undefined && (
                        <span className="ml-2">
                          ì‹ ë¢°ë„: {(item.score * 100).toFixed(1)}%
                        </span>
                      )}
                    </div>
                  </div>
                ))}
            </div>
          </div>
        )}

        {/* ì—°ê²° ëŒ€ê¸° ì¤‘ì¼ ë•Œ í”Œë ˆì´ìŠ¤í™€ë” */}
        {!remoteStream &&
          callStatus !== "ended" &&
          callStatus !== "rejected" && (
            <div className="absolute inset-0 flex items-center justify-center text-white text-lg sm:text-xl">
              ìƒëŒ€ë°©ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...
            </div>
          )}
      </div>

      {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
      <div className="bg-gray-800 flex-shrink-0 p-3 sm:p-4 min-h-[100px] flex items-center justify-center">
        <div className="flex justify-center gap-2 sm:gap-4 w-full max-w-2xl">
          <Button
            onClick={toggleMic}
            variant={isMicOn ? "default" : "destructive"}
            className="flex-1 max-w-[100px] px-2 py-2 text-xs sm:text-sm sm:px-4"
          >
            <span className="hidden sm:inline">
              {isMicOn ? "ë§ˆì´í¬ ì¼œì§" : "ë§ˆì´í¬ êº¼ì§"}
            </span>
            <span className="sm:hidden">{isMicOn ? "ğŸ¤" : "ğŸ”‡"}</span>
          </Button>

          <Button
            onClick={toggleCamera}
            variant={isCameraOn ? "default" : "destructive"}
            className="flex-1 max-w-[100px] px-2 py-2 text-xs sm:text-sm sm:px-4"
          >
            <span className="hidden sm:inline">
              {isCameraOn ? "ì¹´ë©”ë¼ ì¼œì§" : "ì¹´ë©”ë¼ êº¼ì§"}
            </span>
            <span className="sm:hidden">{isCameraOn ? "ğŸ“¹" : "ğŸ“·"}</span>
          </Button>

          {/* AI ê¸°ëŠ¥ í† ê¸€ ë²„íŠ¼ */}
          <Button
            onClick={toggleAI}
            variant={isAIEnabled ? "default" : "outline"}
            className={`flex-1 max-w-[100px] px-2 py-2 text-xs sm:text-sm sm:px-4 ${
              isAIEnabled ? "bg-green-600 hover:bg-green-700" : ""
            }`}
            disabled={isMediaPipeInitializing}
          >
            <span className="hidden sm:inline">{getAIButtonText()}</span>
            <span className="sm:hidden">{getAIButtonIcon()}</span>
          </Button>

          <Button
            onClick={endCall}
            variant="destructive"
            className="flex-1 max-w-[100px] px-2 py-2 text-xs sm:text-sm sm:px-4 bg-red-600 hover:bg-red-700"
          >
            <span className="hidden sm:inline">í†µí™” ì¢…ë£Œ</span>
            <span className="sm:hidden">ğŸ“</span>
          </Button>
        </div>
      </div>
    </div>
  );
}
